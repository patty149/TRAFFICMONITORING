{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINS\\Anaconda3\\envs\\yolo\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolo3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6e258f3a2ccb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myolo3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yolo3'"
     ]
    }
   ],
   "source": [
    "\"\"\"YOLO_v3 Model Defined in Keras.\"\"\"\n",
    "\n",
    "from functools import wraps\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from yolo3.utils import compose\n",
    "\n",
    "\n",
    "@wraps(Conv2D)\n",
    "def DarknetConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
    "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides')==(2,2) else 'same'\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
    "    x = DarknetConv2D_BN_Leaky(num_filters, (3,3), strides=(2,2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "                DarknetConv2D_BN_Leaky(num_filters//2, (1,1)),\n",
    "                DarknetConv2D_BN_Leaky(num_filters, (3,3)))(x)\n",
    "        x = Add()([x,y])\n",
    "    return x\n",
    "\n",
    "def darknet_body(x):\n",
    "    '''Darknent body having 52 Convolution2D layers'''\n",
    "    x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)))(x)\n",
    "    y = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D(out_filters, (1,1)))(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V3 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body(inputs))\n",
    "    x, y1 = make_last_layers(darknet.output, 512, num_anchors*(num_classes+5))\n",
    "\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(256, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x,darknet.layers[152].output])\n",
    "    x, y2 = make_last_layers(x, 256, num_anchors*(num_classes+5))\n",
    "\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(128, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x,darknet.layers[92].output])\n",
    "    x, y3 = make_last_layers(x, 128, num_anchors*(num_classes+5))\n",
    "\n",
    "    return Model(inputs, [y1,y2,y3])\n",
    "\n",
    "def tiny_yolo_body(inputs, num_anchors, num_classes):\n",
    "    '''Create Tiny YOLO_v3 model CNN body in keras.'''\n",
    "    x1 = compose(\n",
    "            DarknetConv2D_BN_Leaky(16, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(32, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(64, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(128, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(256, (3,3)))(inputs)\n",
    "    x2 = compose(\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(512, (3,3)),\n",
    "            MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'),\n",
    "            DarknetConv2D_BN_Leaky(1024, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(256, (1,1)))(x1)\n",
    "    y1 = compose(\n",
    "            DarknetConv2D_BN_Leaky(512, (3,3)),\n",
    "            DarknetConv2D(num_anchors*(num_classes+5), (1,1)))(x2)\n",
    "\n",
    "    x2 = compose(\n",
    "            DarknetConv2D_BN_Leaky(128, (1,1)),\n",
    "            UpSampling2D(2))(x2)\n",
    "    y2 = compose(\n",
    "            Concatenate(),\n",
    "            DarknetConv2D_BN_Leaky(256, (3,3)),\n",
    "            DarknetConv2D(num_anchors*(num_classes+5), (1,1)))([x2,x1])\n",
    "\n",
    "    return Model(inputs, [y1,y2])\n",
    "\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    '''Get corrected boxes'''\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
    "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
    "    new_shape = K.round(image_shape * K.min(input_shape/image_shape))\n",
    "    offset = (input_shape-new_shape)/2./input_shape\n",
    "    scale = input_shape/new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes =  K.concatenate([\n",
    "        box_mins[..., 0:1],  # y_min\n",
    "        box_mins[..., 1:2],  # x_min\n",
    "        box_maxes[..., 0:1],  # y_max\n",
    "        box_maxes[..., 1:2]  # x_max\n",
    "    ])\n",
    "\n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes *= K.concatenate([image_shape, image_shape])\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n",
    "    '''Process Conv layer output'''\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats,\n",
    "        anchors, num_classes, input_shape)\n",
    "    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = K.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = K.reshape(box_scores, [-1, num_classes])\n",
    "    return boxes, box_scores\n",
    "\n",
    "\n",
    "def yolo_eval(yolo_outputs,\n",
    "              anchors,\n",
    "              num_classes,\n",
    "              image_shape,\n",
    "              max_boxes=20,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n",
    "    num_layers = len(yolo_outputs)\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]] # default setting\n",
    "    input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    for l in range(num_layers):\n",
    "        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l],\n",
    "            anchors[anchor_mask[l]], num_classes, input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = K.concatenate(boxes, axis=0)\n",
    "    box_scores = K.concatenate(box_scores, axis=0)\n",
    "\n",
    "    mask = box_scores >= score_threshold\n",
    "    max_boxes_tensor = K.constant(max_boxes, dtype='int32')\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(num_classes):\n",
    "        # TODO: use keras backend instead of tf.\n",
    "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
    "        nms_index = tf.image.non_max_suppression(\n",
    "            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "        class_boxes = K.gather(class_boxes, nms_index)\n",
    "        class_box_scores = K.gather(class_box_scores, nms_index)\n",
    "        classes = K.ones_like(class_box_scores, 'int32') * c\n",
    "        boxes_.append(class_boxes)\n",
    "        scores_.append(class_box_scores)\n",
    "        classes_.append(classes)\n",
    "    boxes_ = K.concatenate(boxes_, axis=0)\n",
    "    scores_ = K.concatenate(scores_, axis=0)\n",
    "    classes_ = K.concatenate(classes_, axis=0)\n",
    "\n",
    "    return boxes_, scores_, classes_\n",
    "\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    '''Preprocess true boxes to training input format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes: array, shape=(m, T, 5)\n",
    "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
    "    input_shape: array-like, hw, multiples of 32\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
    "\n",
    "    '''\n",
    "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh)==0: continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],\n",
    "             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = K.control_flow_ops.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "        if print_loss:\n",
    "            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)], message='loss: ')\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Miscellaneous utility functions.\"\"\"\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "\n",
    "def compose(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "def rand(a=0, b=1):\n",
    "    return np.random.rand()*(b-a) + a\n",
    "\n",
    "def get_random_data(annotation_line, input_shape, random=True, max_boxes=20, jitter=.3, hue=.1, sat=1.5, val=1.5, proc_img=True):\n",
    "    '''random preprocessing for real-time data augmentation'''\n",
    "    line = annotation_line.split()\n",
    "    image = Image.open(line[0])\n",
    "    iw, ih = image.size\n",
    "    h, w = input_shape\n",
    "    box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    if not random:\n",
    "        # resize image\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        dx = (w-nw)//2\n",
    "        dy = (h-nh)//2\n",
    "        image_data=0\n",
    "        if proc_img:\n",
    "            image = image.resize((nw,nh), Image.BICUBIC)\n",
    "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image)/255.\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((max_boxes,5))\n",
    "        if len(box)>0:\n",
    "            np.random.shuffle(box)\n",
    "            if len(box)>max_boxes: box = box[:max_boxes]\n",
    "            box[:, [0,2]] = box[:, [0,2]]*scale + dx\n",
    "            box[:, [1,3]] = box[:, [1,3]]*scale + dy\n",
    "            box_data[:len(box)] = box\n",
    "\n",
    "        return image_data, box_data\n",
    "\n",
    "    # resize image\n",
    "    new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
    "    scale = rand(.25, 2)\n",
    "    if new_ar < 1:\n",
    "        nh = int(scale*h)\n",
    "        nw = int(nh*new_ar)\n",
    "    else:\n",
    "        nw = int(scale*w)\n",
    "        nh = int(nw/new_ar)\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "    # place image\n",
    "    dx = int(rand(0, w-nw))\n",
    "    dy = int(rand(0, h-nh))\n",
    "    new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    image = new_image\n",
    "\n",
    "    # flip image or not\n",
    "    flip = rand()<.5\n",
    "    if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # distort image\n",
    "    hue = rand(-hue, hue)\n",
    "    sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "    val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "    x = rgb_to_hsv(np.array(image)/255.)\n",
    "    x[..., 0] += hue\n",
    "    x[..., 0][x[..., 0]>1] -= 1\n",
    "    x[..., 0][x[..., 0]<0] += 1\n",
    "    x[..., 1] *= sat\n",
    "    x[..., 2] *= val\n",
    "    x[x>1] = 1\n",
    "    x[x<0] = 0\n",
    "    image_data = hsv_to_rgb(x) # numpy array, 0 to 1\n",
    "\n",
    "    # correct boxes\n",
    "    box_data = np.zeros((max_boxes,5))\n",
    "    if len(box)>0:\n",
    "        np.random.shuffle(box)\n",
    "        box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "        box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "        if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
    "        box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "        box[:, 2][box[:, 2]>w] = w\n",
    "        box[:, 3][box[:, 3]>h] = h\n",
    "        box_w = box[:, 2] - box[:, 0]\n",
    "        box_h = box[:, 3] - box[:, 1]\n",
    "        box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
    "        if len(box)>max_boxes: box = box[:max_boxes]\n",
    "        box_data[:len(box)] = box\n",
    "\n",
    "    return image_data, box_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "import utilities\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "# from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "# from yolo3.utils import letterbox_image\n",
    "import os\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "class YOLO(object):\n",
    "#     from sort import Sort\n",
    "    _defaults = {\n",
    "        \"model_path\": 'model_data/yolo.h5',\n",
    "        \"anchors_path\": 'model_data/yolo_anchors.txt',\n",
    "        \"classes_path\": 'model_data/coco_classes.txt',\n",
    "        \"score\" : 0.3,\n",
    "        \"iou\" : 0.45,\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"gpu_num\" : 1,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "#         self.tracker=Sort()\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if self.gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "#         print(out_classes)\n",
    "        final_box=[]\n",
    "        label=[]\n",
    "        scores=[]\n",
    "        for b,lb,sc in zip(out_boxes,out_classes,out_scores):\n",
    "            if lb in [2,3,5,7]:\n",
    "                final_box.append(b)\n",
    "                label.append(lb)\n",
    "                scores.append(sc)\n",
    "#         if len(final_box)==0:    # if no detection then continue the loop\n",
    "\n",
    "#             continue\n",
    "        out_boxes=np.array(final_box)\n",
    "        out_classes=np.array(label)\n",
    "        out_scores=np.array(scores)\n",
    "        final_boxes=np.column_stack((out_boxes,out_scores))\n",
    "        final_boxes = final_boxes[np.logical_and(final_boxes[:, 4] > 0.3, final_boxes[:, 2] -\n",
    "                                                     final_boxes[:, 0] < 600)]\n",
    "\n",
    "            # Apply NMS\n",
    "        indices = utilities.non_max_suppression(final_boxes, 0.9, final_boxes[:, 4])\n",
    "#         print(out_classes)\n",
    "        \n",
    "        out_boxes = [final_boxes[i] for i in indices]\n",
    "        out_classes= [out_classes[i] for i in indices]\n",
    "        out_classes=reversed(out_classes) # for display\n",
    "#         final_b=[]\n",
    "#         final_s=[]\n",
    "#         for b in out_boxes_:\n",
    "#             final_b.append([b[0],b[1],b[2],b[3]])\n",
    "#             final_s.append(b[4])\n",
    "#         out_boxes=np.array(final_b)\n",
    "#         out_scores=np.array(final_s)\n",
    "#         print(final_boxes)\n",
    "        \n",
    "#         print(out_classes)\n",
    "#         print(out_boxes)\n",
    "#         tracker=Sort()\n",
    "        res_track=tracker.update(np.array(out_boxes))\n",
    "        final_b=[]\n",
    "        final_s=[]\n",
    "        for b in res_track:\n",
    "            final_b.append([b[0],b[1],b[2],b[3]])\n",
    "            final_s.append(b[4])\n",
    "        out_boxes=np.array(final_b)\n",
    "        out_scores=np.array(final_s)\n",
    "\n",
    "        print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "#             i_d=ob_id[i]\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            print(label, (left, top), (right, bottom))\n",
    "\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "\n",
    "        end = timer()\n",
    "        print(end - start)\n",
    "        return image,out_boxes\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *\n",
    "\n",
    "def detect_video(yolo, video_path, output_path=\"\"):\n",
    "    import cv2\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    video_FourCC = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_fps       = vid.get(cv2.CAP_PROP_FPS)\n",
    "    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    isOutput = True if output_path != \"\" else False\n",
    "    if isOutput:\n",
    "        print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(video_fps), type(video_size))\n",
    "        out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    tracker=Sort()\n",
    "    frame_num=0\n",
    "    result_track_all_frames=[]\n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        if not return_value:\n",
    "            break\n",
    "        \n",
    "        image = Image.fromarray(frame)\n",
    "#         image = yolo.detect_image(image)\n",
    "#         result = np.asarray(image)\n",
    "        \n",
    "        start = timer()\n",
    "\n",
    "        if yolo.model_image_size != (None, None):\n",
    "            assert yolo.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert yolo.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(yolo.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "#         print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = yolo.sess.run(\n",
    "            [yolo.boxes, yolo.scores, yolo.classes],\n",
    "            feed_dict={\n",
    "                yolo.yolo_model.input: image_data,\n",
    "                yolo.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "#         print(out_classes)\n",
    "        final_box=[]\n",
    "        label=[]\n",
    "        scores=[]\n",
    "        for b,lb,sc in zip(out_boxes,out_classes,out_scores):\n",
    "            if lb in [2,3,5,7]:\n",
    "                final_box.append(b)\n",
    "                label.append(lb)\n",
    "                scores.append(sc)\n",
    "#         if len(final_box)==0:    # if no detection then continue the loop\n",
    "\n",
    "#             continue\n",
    "        out_boxes=np.array(final_box)\n",
    "        out_classes=np.array(label)\n",
    "        out_scores=np.array(scores)\n",
    "        final_boxes=np.column_stack((out_boxes,out_scores))\n",
    "        final_boxes = final_boxes[np.logical_and(final_boxes[:, 4] > 0.3, final_boxes[:, 2] -\n",
    "                                                     final_boxes[:, 0] < 600)]\n",
    "\n",
    "            # Apply NMS\n",
    "        indices = utilities.non_max_suppression(final_boxes, 0.9, final_boxes[:, 4])\n",
    "#         print(out_classes)\n",
    "        \n",
    "        out_boxes = [final_boxes[i] for i in indices]\n",
    "        out_classes= [out_classes[i] for i in indices]\n",
    "        rev=(reversed(out_classes))  # for display in order since yolo reverse the list \n",
    "        out_classes=[]\n",
    "        for r in rev:\n",
    "            out_classes.append(r)\n",
    "        out_classes=np.array(out_classes)\n",
    "        print(' before tracking')\n",
    "        print(len(out_boxes))\n",
    "        bf=out_boxes\n",
    "        res_track=tracker.update(np.array(out_boxes))\n",
    "        result_track_all_frames.append(convert_bbox(res_track,frame_num))\n",
    "        frame_num+=1\n",
    "        \n",
    "    return np.array(result_track_all_frames)\n",
    "#         final_b=[]\n",
    "#         final_s=[]\n",
    "#         for b in res_track:\n",
    "#             final_b.append([b[0],b[1],b[2],b[3]])\n",
    "#             final_s.append(b[4])\n",
    "#         out_boxes=np.array(final_b)\n",
    "#         print(' after tracking')\n",
    "#         print(len(out_boxes))\n",
    "#         af=out_boxes\n",
    "# #         if len(bf)!=len(af):\n",
    "# #             print(bf)\n",
    "# #             print(af)\n",
    "# #             break\n",
    "        \n",
    "#         out_scores=np.array(final_s)\n",
    "#         print(out_classes)\n",
    "#         print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "# #         print('Found {} class for {}'.format(len(out_classes), 'img'))\n",
    "#         font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "#                     size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "#         thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "#         for i, c in reversed(list(enumerate(out_scores))):\n",
    "# #             predicted_class = yolo.class_names[c]\n",
    "#             box = out_boxes[i]\n",
    "#             score = out_scores[i]\n",
    "# #             i_d=ob_id[i]\n",
    "# #             label = '{} {:.2f}'.format(predicted_class, score)\n",
    "#             label = '{:.2f}'.format(score)\n",
    "\n",
    "#             draw = ImageDraw.Draw(image)\n",
    "#             label_size = draw.textsize(label, font)\n",
    "\n",
    "#             top, left, bottom, right = box\n",
    "#             top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "#             left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "#             bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "#             right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "#             print(label, (left, top), (right, bottom))\n",
    "\n",
    "#             if top - label_size[1] >= 0:\n",
    "#                 text_origin = np.array([left, top - label_size[1]])\n",
    "#             else:\n",
    "#                 text_origin = np.array([left, top + 1])\n",
    "#             print(int(c))\n",
    "#             # My kingdom for a good redistributable image drawing library.\n",
    "#             color=len(yolo.colors)\n",
    "#             if int(c) >= color:\n",
    "#                 if (int(c)-color) not in out_scores:\n",
    "#                     c=(int(c)-color)\n",
    "#                 else:\n",
    "#                     for i in range(1,color):\n",
    "                        \n",
    "#                         c=(int(c)-color)+i\n",
    "#                         if c in out_scores:\n",
    "#                             continue\n",
    "#                         else:\n",
    "#                             break\n",
    "#             for i in range(thickness):\n",
    "#                 draw.rectangle(\n",
    "#                     [left + i, top + i, right - i, bottom - i],\n",
    "#                     outline=yolo.colors[int(c)])\n",
    "#             draw.rectangle(\n",
    "#                 [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "#                 fill=yolo.colors[int(c)])\n",
    "#             draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "#             del draw\n",
    "\n",
    "# #         end = timer()\n",
    "# #         print(end - start)\n",
    "#         result = np.asarray(image)\n",
    "\n",
    "#         curr_time = timer()\n",
    "#         exec_time = curr_time - prev_time\n",
    "#         prev_time = curr_time\n",
    "#         accum_time = accum_time + exec_time\n",
    "#         curr_fps = curr_fps + 1\n",
    "#         if accum_time > 1:\n",
    "#             accum_time = accum_time - 1\n",
    "#             fps = \"FPS: \" + str(curr_fps)\n",
    "#             curr_fps = 0\n",
    "#         cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                     fontScale=0.50, color=(255, 0, 0), thickness=2)\n",
    "#         cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "#         cv2.imshow(\"result\", result)\n",
    "#         if isOutput:\n",
    "#             out.write(result)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     yolo.close_session()\n",
    "KalmanBoxTracker.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_bbox(bbox,frame):\n",
    "    \"\"\"\n",
    "    Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "    \"\"\"\n",
    "    final_res=[]\n",
    "    for box in bbox:\n",
    "        res=[]\n",
    "        w = box[2]-box[0]\n",
    "        h = box[3]-box[1]\n",
    "        x = box[0]+w/2.\n",
    "        y = box[1]+h/2.\n",
    "        s = w*h    #scale is just area\n",
    "        r = w/float(h)\n",
    "        res=np.array([x,y,w,h,(box[4]),frame])\n",
    "        final_res.append(res)\n",
    "    return np.array(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "model_data/yolo.h5 model, anchors, and classes loaded.\n"
     ]
    }
   ],
   "source": [
    "yolo=YOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yolo.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 416, 3)\n",
      "<list_reverseiterator object at 0x00000000E4205D68>\n",
      "[array([417.26642  , 397.9517   , 470.48206  , 483.05835  ,   0.9873206],\n",
      "      dtype=float32), array([412.6501    , 268.7779    , 466.36285   , 360.98837   ,\n",
      "         0.98656195], dtype=float32), array([393.984    , 226.96066  , 427.90686  , 276.2052   ,   0.9635404],\n",
      "      dtype=float32), array([395.2049    , 320.19452   , 435.25388   , 379.2594    ,\n",
      "         0.96188474], dtype=float32), array([337.84875  ,   2.5723457, 516.19116  , 187.86516  ,   0.9556708],\n",
      "      dtype=float32)]\n",
      "Found 5 boxes for img\n",
      "car 32.00 (398, 417) (483, 470)\n",
      "car 33.00 (269, 413) (361, 466)\n",
      "car 34.00 (227, 394) (276, 428)\n",
      "car 35.00 (320, 395) (379, 435)\n",
      "truck 36.00 (3, 338) (188, 516)\n",
      "6.786413176884253\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('b.jpg')\n",
    "img =  Image.fromarray(img)\n",
    "img,bbox = yolo.detect_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "ffmpeg_extract_subclip(\"session0_center.avi\", 0, 10, targetname=\"session0_center_10.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "KalmanBoxTracker.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "10\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "10\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "9\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "8\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "7\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n",
      "(416, 416, 3)\n",
      " before tracking\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "res_=detect_video(yolo, video_path='./session0_center_10.avi',\n",
    "#                   output_path='./1.avi'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18068146e+02, 6.18007507e+02, 3.13400265e+01, 3.73836666e+01,\n",
       "        6.00000000e+00, 0.00000000e+00],\n",
       "       [4.45816971e+02, 1.89025525e+03, 5.00594179e+01, 5.33823244e+01,\n",
       "        5.00000000e+00, 0.00000000e+00],\n",
       "       [1.55986404e+02, 2.28830368e+02, 2.24751588e+01, 2.67177736e+01,\n",
       "        4.00000000e+00, 0.00000000e+00],\n",
       "       [2.53844086e+02, 3.98693283e+02, 3.60283818e+01, 5.45788886e+01,\n",
       "        3.00000000e+00, 0.00000000e+00],\n",
       "       [3.66061188e+02, 1.82175140e+02, 7.72827756e+01, 7.99942319e+01,\n",
       "        2.00000000e+00, 0.00000000e+00],\n",
       "       [2.94927078e+02, 4.21924011e+02, 5.41534124e+01, 6.88485115e+01,\n",
       "        1.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('result_cam_cab_10s.pkl','wb') as f:\n",
    "    \n",
    "    pickle.dump(res_,f,protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a2f00cb52eb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "b[:, 5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
